DataFrame是二维表格型数据结构，类似R的data.frame，是Series的容器。

【1】、字典转化为DataFrame
>>> d={'one':pd.Series([1,2,3],index=['a','b','c']),'two':pd.Series([6,6],index=['a','b'])}
>>> df=pd.DataFrame(d)
>>> df
   one  two
a    1  6.0
b    2  6.0
c    3  NaN

【2】、set.option设置输出格式，最多显示行数、列数
>>> pd.set_option('display.max_rows',100)

【3】、describe().T与info()函数的运用
>>> df.info()
<class 'pandas.core.frame.DataFrame'>
Index: 3 entries, a to c
Data columns (total 2 columns):
one    3 non-null int64
two    2 non-null float64
dtypes: float64(1), int64(1)
memory usage: 60.0+ bytes
>>> df.describe().T
     count  mean  std  min  25%  50%  75%  max
one    3.0   2.0  1.0  1.0  1.5  2.0  2.5  3.0
two    2.0   6.0  0.0  6.0  6.0  6.0  6.0  6.0

【4】、根据已有的列，创建新列：map函数映射字典实现
>>> df
   one  two
a    1  6.0
b    2  6.0
c    3  NaN
>>> b={'1':'有数据','2':'有数据','3':'空'}
>>> df['新增列']=df.one.map(b)
>>> df
   one  two  新增列
a    1  6.0  NaN
b    2  6.0  NaN
c    3  NaN  NaN

【5】、sort_values()函数，多列的升降序排列
>>> df.sort_values(by=['one','two'],ascending=[False,True])
   one  two  新增列
c    3  NaN  NaN
b    2  6.0  NaN
a    1  6.0  NaN

【6】、loc（）函数插入行，drop删除行
>>> df.loc['d']=[4,2,7]
>>> df
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN
d    4    2  7.0
>>> df1.drop('d',axis=0,inplace=True)
>>> df1
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN

【7】Dataframe删除列del、drop和pop方法三种方式与insert()插入某列
1、del：直接删除列
2、drop：删除某列，不改变原来的df数据，返回删除后的新表df2。axis为1表示删除列，0表示删除行。inplace为True表示直接对原表修改。
3、pop：取出删除列，改变原来的df数据。
4、改变某一列的位置。如：先删除列，然后在原表df中某列插入被删掉的列。
>>> df
   one  two    a  新增列
a    1  6.0  6.0  NaN
b    2  6.0  6.0  NaN
c    3  NaN  NaN  NaN
>>> del df['a']
>>> df
   one  two  新增列
a    1  6.0  NaN
b    2  6.0  NaN
c    3  NaN  NaN
>>> df2=df.drop('新增列',axis=1,inplace=False)
>>> df2
   one  two
a    1  6.0
b    2  6.0
c    3  NaN
>>> df.insert(1,'add',df.pop('新增列'))
>>> df
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN

【8】、DataFrame去重复数据,drop_duplicates()函数的使用
1、df.drop_duplicates()#不带任何参数，将完全相同的行去重。
2、drop_duplicates(subset=['one'],keep='last')#subset列名称，keep保留哪个
>>> df1
   one two
a    1   6
b    1   6
e    3   3
c    3   3
d    3   4
>>> df1.drop_duplicates()
   one two
a    1   6
e    3   3
d    3   4
>>> df1.drop_duplicates(subset=['one'],keep='last')
   one two
b    1   6
d    3   4

【9】、批量替换replace（）函数的使用
>>> df1
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN
d    4    2  7.0
>>> df1.replace(np.nan,0)
   one  add  two
a    1    0  6.0
b    2    0  6.0
c    3    0  0.0
d    4    2  7.0
>>> df1.replace(np.nan,'空数据')
   one  add  two
a    1  空数据    6
b    2  空数据    6
c    3  空数据  空数据
d    4    2    7

【10】、DataFrame的列重命名rename()函数
>>> df1
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN
d    4    2  7.0
>>> df1.rename(columns={'add':'新增'})
   one   新增  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN
d    4    2  7.0

【11】、DataFrame的三种切片方式，loc(),iloc()与ix()。
loc是location的简写，iloc为integer location的简写。
1、loc（）第一个参数表示行，第二个表示列
2、ix（）自动判断是标签还是位置进行切片。
>>> df
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN
d    4    2  7.0
>>> df.loc[['a','b'],['one','two']]
   one  two
a    1  6.0
b    2  6.0
>>> df.ix[:,'two']
a    6.0
b    6.0
c    NaN
d    7.0
Name: two, dtype: float64

【12】、根据条件进行筛选
>>> df
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
c    3  NaN  NaN
d    4    2  7.0
>>> df[df.two>5]
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
d    4    2  7.0
>>> df[(df.two>5)*1==1]
   one  add  two
a    1  NaN  6.0
b    2  NaN  6.0
d    4    2  7.0

【13】、连续型变量分组，便于区间统计。
1、使用cut（）函数进行切分
>>> df
   one    six  two
a    1   9.12  6.0
b    2  21.03  6.0
c    3  27.03  NaN
d    4   5.45  7.0
>>> bins=[4,9,10,20,30]	#分组区间
>>> cat=pd.cut(df.six,bins)
>>> cat
a     (9, 10]
b    (20, 30]
c    (20, 30]
d      (4, 9]
Name: six, dtype: category
Categories (4, interval[int64]): [(4, 9] < (9, 10] < (10, 20] < (20, 30]]

2、pd.value_counts()函数对区间进行统计
>>> pd.value_counts(cat)
(20, 30]    2
(9, 10]     1
(4, 9]      1
(10, 20]    0
Name: six, dtype: int64

3、对分组标签重新命名，利用pd.cut(labels参数)

>>> group_rename = ['低','较低','较高','高']
>>> pd.cut(df.six,bins,labels=group_rename)
a    较低
b     高
c     高
d     低
Name: six, dtype: category
Categories (4, object): [低 < 较低 < 较高 < 高]

【14】、Pandas分组技术，groupby()函数的运用。
1、agg(）传入多个统计参数

>>> df
   one    six  two
a  1.0   9.12  6.0
b  2.0  21.03  6.0
c  3.0  27.03  NaN
d  4.0   5.45  7.0
e  4.0   6.00  6.0
>>> df['six'].groupby(df['one']).count()#计数
one
1.0    1
2.0    1
3.0    1
4.0    2
Name: six, dtype: int64
>>> df['six'].groupby(df['one']).sum()#求和
one
1.0     9.12
2.0    21.03
3.0    27.03
4.0    11.45
Name: six, dtype: float64
>>> df[['six','two']].groupby(df['one']).agg({'six':['sum'],'two':['count']})
       six   two
       sum count
one
1.0   9.12     1
2.0  21.03     1
3.0  27.03     0
4.0  11.45     2

【15】、Pandas分组技术，apply()函数的运用。
>>> df.groupby(df['one']).apply(lambda x:x[:1])	#只显示一行
       one    six  two
one
1.0 a  1.0   9.12  6.0
2.0 b  2.0  21.03  6.0
3.0 c  3.0  27.03  NaN
4.0 d  4.0   5.45  7.0
>>> df.groupby(df['one']).apply(lambda x:x.sum()) #求和
     one    six   two
one
1.0  1.0   9.12   6.0
2.0  2.0  21.03   6.0
3.0  3.0  27.03   0.0
4.0  8.0  11.45  13.0

【16】、两个DataFrame的合并，append()函数的使用。注意：列名称必须保持一致
>>> df=pd.DataFrame([[1,2],[3,4]],columns=['a','b'])
>>> df
   a  b
0  1  2
1  3  4
>>> df1
   a  b
0  5  6
1  7  8
>>> df2=df.append(df1)
>>> df2
   a  b
0  1  2
1  3  4
0  5  6
1  7  8
>>> df2=df.append(df1,ignore_index=True)#ignore_index重新进行排序
>>> df2
   a  b
0  1  2
1  3  4
2  5  6
3  7  8

【17】、将多个DataFrame的合并，concat（）函数的使用

res = pd.concat([df1,df2,df3],axis=0,ignore_index=True)
参数axis=0表示上下合并，1表示左右合并，ignore_index=True表示忽略原来的索引



